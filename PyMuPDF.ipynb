{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz # import PyMuPDF\n",
    "# import json\n",
    "# import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "# import re\n",
    "\n",
    "# import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# from adobe.pdfservices.operation.auth.credentials import Credentials\n",
    "# from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "# from adobe.pdfservices.operation.execution_context import ExecutionContext\n",
    "# from adobe.pdfservices.operation.io.file_ref import FileRef\n",
    "# from adobe.pdfservices.operation.pdfops.extract_pdf_operation import ExtractPDFOperation\n",
    "# from adobe.pdfservices.operation.pdfops.options.extractpdf.extract_pdf_options import ExtractPDFOptions\n",
    "# from adobe.pdfservices.operation.pdfops.options.extractpdf.extract_element_type import ExtractElementType\n",
    "\n",
    "path = 'C://Users//nhagl//Desktop//work//demo//ComplianceTool//adobe_api//pdfs'\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for pdf_name in dir_list:\n",
    "    # zip_file = \"./ExtractTextFrom\" +pdf_name.replace(\".pdf\",\"\") + \".zip\"\n",
    "    # input_pdf = \"./pdfs/\" + pdf_name\n",
    "\n",
    "    # if not os.path.isfile(zip_file):\n",
    "    #     #Initial setup, create credentials instance.\n",
    "    #     credentials = Credentials.service_account_credentials_builder()\\\n",
    "    #         .from_file(\"./pdfservices-api-credentials.json\") \\\n",
    "    #         .build()\n",
    "\n",
    "    #     #Create an ExecutionContext using credentials and create a new operation instance.\n",
    "    #     execution_context = ExecutionContext.create(credentials)\n",
    "\n",
    "    #     extract_pdf_operation = ExtractPDFOperation.create_new()\n",
    "\n",
    "    #     #Set operation input from a source file.\n",
    "    #     source = FileRef.create_from_local_file(input_pdf)\n",
    "    #     extract_pdf_operation.set_input(source)\n",
    "\n",
    "    #     #Build ExtractPDF options and set them into the operation\n",
    "    #     extract_pdf_options: ExtractPDFOptions = ExtractPDFOptions.builder() \\\n",
    "    #         .with_element_to_extract(ExtractElementType.TEXT) \\\n",
    "    #         .build()\n",
    "    #     extract_pdf_operation.set_options(extract_pdf_options)\n",
    "\n",
    "    #     #Execute the operation.\n",
    "    #     result: FileRef = extract_pdf_operation.execute(execution_context)\n",
    "\n",
    "    #     #Save the result to the specified location.\n",
    "    #     result.save_as(zip_file)\n",
    "\n",
    "    # archive = zipfile.ZipFile(zip_file, 'r')\n",
    "    # jsonentry = archive.open('structuredData.json')\n",
    "    # jsondata = jsonentry.read()\n",
    "    # data = json.loads(jsondata)\n",
    "\n",
    "    # header_list = []\n",
    "    # for element in data[\"elements\"]:\n",
    "    #     if(\"TOC\" in element[\"Path\"]) or (\"H\" in element[\"Path\"]):\n",
    "    #         try:\n",
    "    #             header_list.append(element[\"Text\"])\n",
    "    #         except:\n",
    "    #             continue\n",
    "    \n",
    "    # pattern = re.compile(r'\\s+')\n",
    "    # reduced_string = \"\"\n",
    "    # reduced_list = []\n",
    "    # for header in header_list:\n",
    "    #     reduced_string += re.sub(pattern, '', header)\n",
    "    #     reduced_list.append(re.sub(pattern, '', header))\n",
    "\n",
    "    doc = fitz.open(\"./pdfs/\" + pdf_name) # open a supported document\n",
    "    index = 0\n",
    "    whole_document = []\n",
    "    while index < doc.page_count:\n",
    "        page = doc[index] # load the required page (0-based index)\n",
    "        whole_document.append(page.get_text(\"dict\", sort=True))\n",
    "        index += 1\n",
    "        # text = page.get_text(\"dict\", sort=True) # extract plain text\n",
    "        # # print(text) # process or print it:\n",
    "        # print(json.dumps(text, indent=4)\n",
    "    final_list = []\n",
    "    for page in whole_document:\n",
    "        page_width = page['width']\n",
    "        page_height = page['height']\n",
    "        for i in page['blocks']:\n",
    "            try: \n",
    "                for line in i['lines']:\n",
    "\n",
    "                    text_line = \"\"\n",
    "                    span_list = []\n",
    "                    font_size = 0\n",
    "                    font_family = \"\"\n",
    "                    font_weight = 0\n",
    "                    page_number = whole_document.index(page) + 1\n",
    "                    x_origin = line['bbox'][0]\n",
    "                    x_end = line['bbox'][2]\n",
    "                    y_origin = line['bbox'][1]\n",
    "                    y_end = line['bbox'][3]\n",
    "                    # header = 0\n",
    "                    for span in line['spans']:\n",
    "                        try:\n",
    "                            text_line += span['text']\n",
    "                            span_list.append(span['text'])\n",
    "                        except:\n",
    "                            continue\n",
    "                        try:\n",
    "                            if span[\"size\"] > font_size:\n",
    "                                font_size = span[\"size\"]\n",
    "                        except:\n",
    "                            continue\n",
    "                        try:\n",
    "                            if \"Bold\" in span[\"font\"]:\n",
    "                                font_weight = 1\n",
    "                                font_family = span[\"font\"]\n",
    "                            elif \"Underline\" in span[\"font\"]:\n",
    "                                font_weight = 1\n",
    "                                font_family = span[\"font\"]\n",
    "                            elif \"Ital\" in span[\"font\"]:\n",
    "                                font_weight = 1\n",
    "                                font_family = span[\"font\"]\n",
    "                            elif (\"Bold\" not in font_family) and (\"Underline\" not in font_family) and (\"Italic\" not in font_family):\n",
    "                                font_family = span[\"font\"]\n",
    "                        except:\n",
    "                            continue\n",
    "                    # pattern = re.compile(r'\\s+')\n",
    "                    # if re.sub(pattern, '', text_line) in reduced_list:\n",
    "                    #     header = 1\n",
    "                    # else:\n",
    "                    #     for item in span_list:\n",
    "                    #         if re.sub(pattern, '', item) in reduced_list:\n",
    "                    #             header = 1\n",
    "                    if text_line.isspace() or text_line == \"\":\n",
    "                        continue\n",
    "                    else:\n",
    "                        final_list.append({\n",
    "                            'Text Line' : text_line.encode('utf8'),\n",
    "                            'Font Size' : font_size,\n",
    "                            'Font Family' : font_family,\n",
    "                            'Font Weight': font_weight,\n",
    "                            'Page Number': page_number,\n",
    "                            'X Origin': x_origin,\n",
    "                            'X End': x_end,\n",
    "                            'Y Origin': y_origin,\n",
    "                            'Y End': y_end,\n",
    "                            'Page Width': page_width,\n",
    "                            'Page Height': page_height,\n",
    "                            'Document': pdf_name\n",
    "                        })\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    keys = final_list[0].keys()\n",
    "\n",
    "    with open('test.csv', 'w', newline='') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, keys)\n",
    "        # dict_writer.writeheader()\n",
    "        dict_writer.writerows(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# df = df.append({\n",
    "#     'Text Line' : 'Stuff', #complete text line\n",
    "#     'Font Size' : 30, #max occurence of font size in line\n",
    "#     'Font Family' : 50, #max occurence of font family in line\n",
    "#     'Font Weight': 1, #max occurence of font weight in line\n",
    "#     'Page Number': 1, #index + 1 of line\n",
    "#     'X Origin': 1, #['bbox'][0] for line\n",
    "#     'X End': 2, #['bbox'][2] for line\n",
    "#     'Y Origin': 1, #['bbox'][1] for line\n",
    "#     'Y End': 1, #['bbox'][3] for line\n",
    "#     'Page Width': 20,\n",
    "#     'Page Height': 25\n",
    "#     },ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd7ee25e52437abfcc1be8769f74abebaaef7502d24ddb76de6f25355860e166"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
